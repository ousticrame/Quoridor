{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSP Solver for Wordle game\n",
    "\n",
    "### Useful links :\n",
    "- [Medium article](https://medium.com/better-programming/beating-wordle-constraint-programming-ef0b0b6897fe#:~:text=Beating%20Wordle%3A%20Constraint%20Programming,Wordle%20solver%20do%20its%20thing)\n",
    "- [Sample dataset (GitHub)](https://github.com/dwyl/english-words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "\n",
    "# We import all the english words inside this dataset\n",
    "total_words = pd.read_fwf(\"words_alpha.txt\", names=[\"words\"])\n",
    "\n",
    "# Keep only the 5 letter words\n",
    "words = total_words[total_words[\"words\"].str.len() == 5]\n",
    "\n",
    "# We convert the words into a list of integers (A -> 0, B -> 1, ..., Z -> 25)\n",
    "words_data = [tuple([ord(c) - ord('a') for c in word]) for word in words[\"words\"]]\n",
    "\n",
    "# We initialise the letter statistics for the heuristic function\n",
    "# Positional frequency (frequency of letters at each position)\n",
    "positional_freq = [defaultdict(int) for _ in range(5)]\n",
    "for word in words_data:\n",
    "    for pos in range(5):\n",
    "        char = word[pos]\n",
    "        positional_freq[pos][char] += 1\n",
    "\n",
    "# Letter frequency (frequency of letters in the dataset)\n",
    "letter_frequency = Counter(itertools.chain.from_iterable(words_data))\n",
    "\n",
    "# Normalize the letter frequencies\n",
    "total_words = len(words_data)\n",
    "for char, freq in letter_frequency.items():\n",
    "    letter_frequency[char] = freq / total_words\n",
    "\n",
    "# Normalize the positional frequencies\n",
    "for pos in range(5):\n",
    "    total_pos = sum(positional_freq[pos].values())\n",
    "    for char, freq in positional_freq[pos].items():\n",
    "        positional_freq[pos][char] = freq / total_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random word: lindy\n",
      "\n",
      "Positional frequency: [defaultdict(<class 'int'>, {0: 0.07373908674078261, 1: 0.0716663526160417, 2: 0.07518371961560204, 3: 0.05031091011871114, 4: 0.026443062621694616, 5: 0.04296212549462974, 6: 0.04629106211921362, 7: 0.03586458137051693, 24: 0.010489290873688838, 8: 0.01890584762263677, 9: 0.016330632497958672, 10: 0.029709189121286353, 11: 0.04264807486966899, 12: 0.053325796118334275, 13: 0.025500910746812388, 14: 0.020978581747377677, 15: 0.0592927579925884, 16: 0.005338860624332643, 17: 0.04277369511965329, 18: 0.11387475661076565, 19: 0.06161673261729791, 20: 0.020601720997424786, 21: 0.018026505872746686, 22: 0.029395138496325607, 23: 0.0016958733747880158, 25: 0.007034733999120658}), defaultdict(<class 'int'>, {0: 0.18032786885245902, 1: 0.006846303624144212, 2: 0.015953771748005777, 3: 0.008542176998932227, 4: 0.12379875635952516, 5: 0.0025124049996859492, 6: 0.006406632749199171, 7: 0.04522328999434709, 24: 0.017586834997801646, 8: 0.10483009861189624, 9: 0.0011933923748508259, 10: 0.006343822624207022, 11: 0.0543935682432008, 12: 0.014634759123170655, 13: 0.03498523962062684, 14: 0.14326989510709126, 15: 0.01777526537277809, 16: 0.0013190126248351234, 17: 0.0722944538659632, 18: 0.010866151623641731, 19: 0.019847999497519, 20: 0.08812260536398467, 21: 0.005087620124364048, 22: 0.01092896174863388, 23: 0.0046479492494190065, 25: 0.0022611644997173543}), defaultdict(<class 'int'>, {7: 0.013064505998366937, 11: 0.06664154261666981, 17: 0.0970416431128698, 0: 0.09302179511337227, 1: 0.028076125871490484, 3: 0.03228440424596445, 4: 0.06450599836693675, 8: 0.07958042836505244, 24: 0.01438351862320206, 10: 0.01940832862257396, 12: 0.04076377111990453, 13: 0.07775893474028013, 14: 0.07248288424093964, 18: 0.04283650524464544, 20: 0.04943156836882105, 22: 0.017335594497833052, 2: 0.03335217637083098, 19: 0.04918032786885246, 5: 0.01243640474844545, 9: 0.003580177124552478, 15: 0.02725959424659255, 25: 0.008981847873877269, 6: 0.028955467621380567, 16: 0.0016958733747880158, 21: 0.018026505872746686, 23: 0.00791407574901074}), defaultdict(<class 'int'>, {4: 0.15771622385528547, 8: 0.08297217511462848, 6: 0.029960429621254947, 14: 0.05671754286791031, 2: 0.03404308774574461, 3: 0.03423151812072106, 5: 0.013504176873311978, 10: 0.030400100496199987, 12: 0.02926951824634131, 13: 0.05866465674266692, 18: 0.045286100119339236, 19: 0.06400351736699957, 20: 0.043087745744614034, 21: 0.012562024998429747, 25: 0.008102506123987187, 0: 0.09955404811255575, 11: 0.05797374536775328, 17: 0.054770428993153694, 7: 0.018089315997738834, 15: 0.026631492996671065, 24: 0.010112430123735945, 22: 0.009986809873751648, 1: 0.018654607122668174, 23: 0.0011305822498586771, 9: 0.0023867847497016518, 16: 0.0001884303749764462}), defaultdict(<class 'int'>, {3: 0.051315872118585515, 8: 0.03197035362100371, 7: 0.03121663212109792, 13: 0.0570944036178632, 0: 0.08052258023993468, 10: 0.023616606997047925, 5: 0.006343822624207022, 19: 0.06846303624144212, 15: 0.01344136674831983, 4: 0.11764336411029458, 18: 0.1977262734752842, 24: 0.10589787073676277, 11: 0.045097669744362794, 12: 0.018654607122668174, 17: 0.056277871992965266, 14: 0.03435713837070536, 22: 0.005904151749261981, 25: 0.0033917467495760316, 1: 0.006092582124238427, 20: 0.009861189623767351, 6: 0.012185164248476854, 2: 0.01388103762326487, 23: 0.007285974499089253, 21: 0.0014446328748194208, 16: 0.0001884303749764462, 9: 0.00012562024998429746})]\n",
      "Letter frequency: Counter({0: 0.5271653790591043, 4: 0.4901074053137366, 18: 0.41058978707367627, 14: 0.3278060423340243, 17: 0.32315809308460525, 8: 0.3182589033352176, 11: 0.2667546008416557, 19: 0.26311161359211105, 13: 0.2540041454682495, 20: 0.2111048300986119, 3: 0.1766848816029144, 2: 0.1724137931034483, 24: 0.15846994535519127, 12: 0.15664845173041894, 15: 0.14440047735694994, 7: 0.14345832548206772, 1: 0.131335971358583, 6: 0.12379875635952516, 10: 0.10947804786131525, 5: 0.07775893474028013, 22: 0.07355065636580617, 21: 0.055147289743106585, 25: 0.0297719992462785, 9: 0.023616606997047925, 23: 0.022674455122165694, 16: 0.008730607373908674})\n",
      "\n",
      "Length of possible words: 15921\n",
      "Is lindy in the dataset? True\n",
      "status = OPTIMAL\n",
      "\n",
      "Attempt 1: tares → ['B', 'B', 'B', 'B', 'B']\n",
      "Length of possible words: 1156\n",
      "Is lindy in the dataset? True\n",
      "status = OPTIMAL\n",
      "\n",
      "Attempt 2: colin → ['B', 'B', 'Y', 'Y', 'Y']\n",
      "Length of possible words: 21\n",
      "Is lindy in the dataset? True\n",
      "status = OPTIMAL\n",
      "\n",
      "Attempt 3: lindy → ['G', 'G', 'G', 'G', 'G']\n",
      "Solved lindy in 3 attempts!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from ortools.sat.python import cp_model\n",
    "import random\n",
    "\n",
    "\n",
    "def get_feedback(guess, target):\n",
    "    \"\"\"\n",
    "    Get the feedback for a given guess and target word and checks duplicate letters\n",
    "    (G: green, B: black, Y: yellow)\n",
    "    \n",
    "    Example:\n",
    "        guess = \"leave\"\n",
    "        target = \"place\"\n",
    "        returns : ['Y', 'B', 'G', 'B', 'G']\n",
    "    \"\"\"\n",
    "    feedback = []\n",
    "    target_counts = Counter(target)\n",
    "    for g_char, t_char in zip(guess, target):\n",
    "        if g_char == t_char:\n",
    "            feedback.append('G')\n",
    "            target_counts[g_char] -= 1\n",
    "        else:\n",
    "            feedback.append('B')\n",
    "\n",
    "    # Second pass for yellows\n",
    "    for pos, (g_char, t_char) in enumerate(zip(guess, target)):\n",
    "        if feedback[pos] == 'B' and g_char in target_counts and target_counts[g_char] > 0:\n",
    "            feedback[pos] = 'Y'\n",
    "            target_counts[g_char] -= 1\n",
    "    return feedback\n",
    "\n",
    "\n",
    "def update_model(model, position_vars, guess, feedback):\n",
    "    \"\"\"\n",
    "    Update the model using the new feedback\n",
    "    \"\"\"\n",
    "    letter_counts = defaultdict(int)    # Key: letter, Value: count\n",
    "    gray_positions = defaultdict(list)  # Key: letter, Value: list of positions\n",
    "\n",
    "    for pos in range(5):\n",
    "        char = guess[pos]\n",
    "        fb = feedback[pos]\n",
    "        if fb == 'G':\n",
    "            model.Add(position_vars[pos] == char)\n",
    "            letter_counts[char] += 1\n",
    "        elif fb == 'Y':\n",
    "            model.Add(position_vars[pos] != char)\n",
    "            letter_counts[char] += 1\n",
    "        elif fb == 'B':\n",
    "            # Track gray letters for their specific positions\n",
    "            gray_positions[char].append(pos)\n",
    "\n",
    "    # Apply gray constraints only to their original positions\n",
    "    for char, positions in gray_positions.items():\n",
    "        for pos in positions:\n",
    "            model.Add(position_vars[pos] != char)\n",
    "\n",
    "    # Enforce letter counts for Y/G (only if not overridden by grays)\n",
    "    for char, count in letter_counts.items():\n",
    "        occurs = [model.NewBoolVar(f'occurs_{p}_{char}') for p in range(5)]\n",
    "        for p in range(5):\n",
    "            if p not in gray_positions.get(char, []):  # Skip gray positions\n",
    "                model.Add(position_vars[p] == char).OnlyEnforceIf(occurs[p])\n",
    "                model.Add(position_vars[p] != char).OnlyEnforceIf(occurs[p].Not())\n",
    "        model.Add(sum(occurs) >= count)\n",
    "    \n",
    "\n",
    "def update_heuristic(model, position_vars):\n",
    "    \"\"\"\n",
    "    Update the heuristic function to maximize for the model\n",
    "    \"\"\"\n",
    "    # Define the coefficients for the heuristic\n",
    "    # (FYI: the frequencies are not normalized)\n",
    "    c_pos_freq = 1000\n",
    "    c_letter_freq = 2000\n",
    "    c_dup = 500\n",
    "\n",
    "    # Build the heuristic objective function\n",
    "    objective = []\n",
    "    for pos in range(5):\n",
    "        char_var = position_vars[pos]\n",
    "        for char in range(26):\n",
    "            is_char = model.NewBoolVar(f'pos_{pos}_char_{char}')\n",
    "            model.Add(char_var == char).OnlyEnforceIf(is_char)\n",
    "            model.Add(char_var != char).OnlyEnforceIf(is_char.Not())\n",
    "            \n",
    "            # Calculate the score based on letter frequencies\n",
    "            score = int(c_pos_freq * positional_freq[pos][char] + c_letter_freq * letter_frequency[char])\n",
    "            objective.append(is_char * score)\n",
    "                \n",
    "    # Calculate the number of duplicates\n",
    "    num_duplicates = model.NewIntVar(0, 25, 'num_duplicates')\n",
    "    char_counts = []\n",
    "    for char in range(26):\n",
    "        count = sum([model.NewBoolVar(f'pos_{i}_char_{char}') for i in range(5)])\n",
    "        for i, pos_var in enumerate(position_vars):\n",
    "            is_char = model.NewBoolVar(f'pos_{i}_is_char_{char}')\n",
    "            model.Add(pos_var == char).OnlyEnforceIf(is_char)\n",
    "            model.Add(pos_var != char).OnlyEnforceIf(is_char.Not())\n",
    "            count += is_char\n",
    "        char_counts.append(count)\n",
    "\n",
    "    # Add constraints to calculate the number of duplicates\n",
    "    duplicates = []\n",
    "    for count in char_counts:\n",
    "        is_duplicate = model.NewBoolVar(f'is_duplicate_{count}')\n",
    "        model.Add(count > 1).OnlyEnforceIf(is_duplicate)\n",
    "        model.Add(count <= 1).OnlyEnforceIf(is_duplicate.Not())\n",
    "        duplicates.append(is_duplicate)\n",
    "\n",
    "    model.Add(num_duplicates == sum(duplicates))\n",
    "\n",
    "    # Penalize the objective based on number of duplicates\n",
    "    objective.append(-c_dup * num_duplicates)\n",
    "\n",
    "    model.Maximize(sum(objective))\n",
    "\n",
    "\n",
    "def list_constraints(model):\n",
    "    \"\"\"\n",
    "    Helper function to list all constraints in the model\n",
    "    \"\"\"\n",
    "    model_proto = model.Proto()\n",
    "    for i, ct in enumerate(model_proto.constraints):\n",
    "        print(f\"Constraint {i}: {ct}\")\n",
    "\n",
    "\n",
    "def filter_valid_words(words_data, guess, feedback):\n",
    "    \"\"\"\n",
    "    Filter all the valid words based on the guess and feedback\n",
    "    \"\"\"\n",
    "    valid = []\n",
    "    for word in words_data:\n",
    "        valid_word = True\n",
    "        # Check green constraints\n",
    "        for pos in range(5):\n",
    "            if feedback[pos] == 'G' and word[pos] != guess[pos]:\n",
    "                valid_word = False\n",
    "                break\n",
    "        if not valid_word:\n",
    "            continue\n",
    "\n",
    "        # Check yellow constraints\n",
    "        for pos in range(5):\n",
    "            if feedback[pos] == 'Y':\n",
    "                if word[pos] == guess[pos] or guess[pos] not in word:\n",
    "                    valid_word = False\n",
    "                    break\n",
    "        if not valid_word:\n",
    "            continue\n",
    "        \n",
    "        # Check gray constraints\n",
    "        gray_chars = [guess[pos] for pos in range(5) if feedback[pos] == 'B']\n",
    "        for char in gray_chars:\n",
    "            if char in word and char not in [guess[p] for p in range(5) if feedback[p] in ('G', 'Y')]:\n",
    "                valid_word = False\n",
    "                break\n",
    "\n",
    "        if valid_word:\n",
    "            valid.append(word)\n",
    "    return valid\n",
    "\n",
    "\n",
    "def solve_wordle(target_word, max_attempts=6, print_output=True):\n",
    "    \"\"\"\n",
    "    Main function to initialize and run the solver\n",
    "\n",
    "    Args:\n",
    "        target_word: the word to solve\n",
    "        max_attempts: the maximum number of attempts to solve the word\n",
    "        print_output: whether to print the output of each attempt\n",
    "\n",
    "    Returns:\n",
    "        number of tries needed to solve the word (doesn't indicate success)\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the model and the valid words\n",
    "    target_as_int = [ord(c) - ord('a') for c in target_word]\n",
    "    valid_words = words_data.copy()  # Use a copy to avoid modifying the original\n",
    "\n",
    "    # Initialize the model and the variables for our model\n",
    "    model = cp_model.CpModel()\n",
    "    position_vars = [model.NewIntVar(0, 25, f'pos_{i}') for i in range(5)]\n",
    "    status_dict = {\n",
    "        cp_model.OPTIMAL: \"OPTIMAL\",\n",
    "        cp_model.FEASIBLE: \"FEASIBLE\",\n",
    "        cp_model.INFEASIBLE: \"INFEASIBLE\",\n",
    "        cp_model.MODEL_INVALID: \"MODEL_INVALID\",\n",
    "        cp_model.UNKNOWN: \"UNKNOWN\"\n",
    "    }\n",
    "\n",
    "    if print_output:    \n",
    "        print(f\"\\nPositional frequency: {positional_freq}\")\n",
    "        print(f\"Letter frequency: {letter_frequency}\\n\")\n",
    "    \n",
    "    for attempt in range(max_attempts):\n",
    "        if print_output:\n",
    "            print(f\"Length of possible words: {len(valid_words)}\")\n",
    "            print(f\"Is {target_word} in the dataset? {tuple(target_as_int) in valid_words}\")\n",
    "\n",
    "        # Reduce the list of all possible words \n",
    "        model.AddAllowedAssignments(position_vars, valid_words)\n",
    "\n",
    "        # Initialize / update the heuristic function\n",
    "        update_heuristic(model, position_vars)\n",
    "\n",
    "        # Initialize and run the solver\n",
    "        solver = cp_model.CpSolver()\n",
    "        status = solver.Solve(model)\n",
    "        if print_output:\n",
    "            print(f\"status = {status_dict.get(status, 'UNKNOWN')}\")\n",
    "\n",
    "        if status == cp_model.OPTIMAL or status == cp_model.FEASIBLE:\n",
    "            # Extract the guess and feedback\n",
    "            guess = tuple([solver.Value(pos) for pos in position_vars])\n",
    "            valid_words.remove(guess)\n",
    "            guess_str = ''.join([chr(c + ord('a')) for c in guess])\n",
    "            feedback = get_feedback(guess, target_as_int)\n",
    "            if print_output:\n",
    "                print(f\"\\nAttempt {attempt+1}: {guess_str} → {feedback}\")\n",
    "            \n",
    "            if feedback == ['G'] * 5:\n",
    "                print(f\"Solved {target_word} in {attempt+1} attempts!\")\n",
    "                return attempt + 1\n",
    "            \n",
    "            # Remove invalid words and update the model\n",
    "            valid_words = filter_valid_words(valid_words, guess, feedback)\n",
    "            update_model(model, position_vars, guess, feedback)\n",
    "        \n",
    "        else:\n",
    "            print(\"Model is infeasible. Exiting.\")\n",
    "            return attempt + 1\n",
    "        \n",
    "    print(f\"Failed to solve {target_word} in {max_attempts} attempts.\")\n",
    "    return max_attempts\n",
    "\n",
    "# Example test\n",
    "# for i in range(5):\n",
    "#     random_word = random.choice(words[\"words\"].to_list())\n",
    "#     print(f\"Random word: {random_word}\")\n",
    "#     solve_wordle(random_word, 100)\n",
    "\n",
    "random_word = random.choice(words[\"words\"].to_list())\n",
    "print(f\"Random word: {random_word}\")\n",
    "solve_wordle(random_word, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other implementation, naive version without constraint model\n",
    "This version only uses the score for each model picks the word with the best score.\n",
    "\n",
    "It doesn't use google OR-TOOLS and is noticeably faster for almost same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positional_freq: [defaultdict(<class 'int'>, {0: 0.07373908674078261, 1: 0.0716663526160417, 2: 0.07518371961560204, 3: 0.05031091011871114, 4: 0.026443062621694616, 5: 0.04296212549462974, 6: 0.04629106211921362, 7: 0.03586458137051693, 24: 0.010489290873688838, 8: 0.01890584762263677, 9: 0.016330632497958672, 10: 0.029709189121286353, 11: 0.04264807486966899, 12: 0.053325796118334275, 13: 0.025500910746812388, 14: 0.020978581747377677, 15: 0.0592927579925884, 16: 0.005338860624332643, 17: 0.04277369511965329, 18: 0.11387475661076565, 19: 0.06161673261729791, 20: 0.020601720997424786, 21: 0.018026505872746686, 22: 0.029395138496325607, 23: 0.0016958733747880158, 25: 0.007034733999120658}), defaultdict(<class 'int'>, {0: 0.18032786885245902, 1: 0.006846303624144212, 2: 0.015953771748005777, 3: 0.008542176998932227, 4: 0.12379875635952516, 5: 0.0025124049996859492, 6: 0.006406632749199171, 7: 0.04522328999434709, 24: 0.017586834997801646, 8: 0.10483009861189624, 9: 0.0011933923748508259, 10: 0.006343822624207022, 11: 0.0543935682432008, 12: 0.014634759123170655, 13: 0.03498523962062684, 14: 0.14326989510709126, 15: 0.01777526537277809, 16: 0.0013190126248351234, 17: 0.0722944538659632, 18: 0.010866151623641731, 19: 0.019847999497519, 20: 0.08812260536398467, 21: 0.005087620124364048, 22: 0.01092896174863388, 23: 0.0046479492494190065, 25: 0.0022611644997173543}), defaultdict(<class 'int'>, {7: 0.013064505998366937, 11: 0.06664154261666981, 17: 0.0970416431128698, 0: 0.09302179511337227, 1: 0.028076125871490484, 3: 0.03228440424596445, 4: 0.06450599836693675, 8: 0.07958042836505244, 24: 0.01438351862320206, 10: 0.01940832862257396, 12: 0.04076377111990453, 13: 0.07775893474028013, 14: 0.07248288424093964, 18: 0.04283650524464544, 20: 0.04943156836882105, 22: 0.017335594497833052, 2: 0.03335217637083098, 19: 0.04918032786885246, 5: 0.01243640474844545, 9: 0.003580177124552478, 15: 0.02725959424659255, 25: 0.008981847873877269, 6: 0.028955467621380567, 16: 0.0016958733747880158, 21: 0.018026505872746686, 23: 0.00791407574901074}), defaultdict(<class 'int'>, {4: 0.15771622385528547, 8: 0.08297217511462848, 6: 0.029960429621254947, 14: 0.05671754286791031, 2: 0.03404308774574461, 3: 0.03423151812072106, 5: 0.013504176873311978, 10: 0.030400100496199987, 12: 0.02926951824634131, 13: 0.05866465674266692, 18: 0.045286100119339236, 19: 0.06400351736699957, 20: 0.043087745744614034, 21: 0.012562024998429747, 25: 0.008102506123987187, 0: 0.09955404811255575, 11: 0.05797374536775328, 17: 0.054770428993153694, 7: 0.018089315997738834, 15: 0.026631492996671065, 24: 0.010112430123735945, 22: 0.009986809873751648, 1: 0.018654607122668174, 23: 0.0011305822498586771, 9: 0.0023867847497016518, 16: 0.0001884303749764462}), defaultdict(<class 'int'>, {3: 0.051315872118585515, 8: 0.03197035362100371, 7: 0.03121663212109792, 13: 0.0570944036178632, 0: 0.08052258023993468, 10: 0.023616606997047925, 5: 0.006343822624207022, 19: 0.06846303624144212, 15: 0.01344136674831983, 4: 0.11764336411029458, 18: 0.1977262734752842, 24: 0.10589787073676277, 11: 0.045097669744362794, 12: 0.018654607122668174, 17: 0.056277871992965266, 14: 0.03435713837070536, 22: 0.005904151749261981, 25: 0.0033917467495760316, 1: 0.006092582124238427, 20: 0.009861189623767351, 6: 0.012185164248476854, 2: 0.01388103762326487, 23: 0.007285974499089253, 21: 0.0014446328748194208, 16: 0.0001884303749764462, 9: 0.00012562024998429746})]\n",
      "letter_frequency: Counter({0: 0.5271653790591043, 4: 0.4901074053137366, 18: 0.41058978707367627, 14: 0.3278060423340243, 17: 0.32315809308460525, 8: 0.3182589033352176, 11: 0.2667546008416557, 19: 0.26311161359211105, 13: 0.2540041454682495, 20: 0.2111048300986119, 3: 0.1766848816029144, 2: 0.1724137931034483, 24: 0.15846994535519127, 12: 0.15664845173041894, 15: 0.14440047735694994, 7: 0.14345832548206772, 1: 0.131335971358583, 6: 0.12379875635952516, 10: 0.10947804786131525, 5: 0.07775893474028013, 22: 0.07355065636580617, 21: 0.055147289743106585, 25: 0.0297719992462785, 9: 0.023616606997047925, 23: 0.022674455122165694, 16: 0.008730607373908674})\n",
      "Random word: idist\n",
      "Attempt 1: tares → ['Y', 'B', 'B', 'B', 'Y']\n",
      "Attempt 2: silty → ['Y', 'Y', 'B', 'Y', 'B']\n",
      "Attempt 3: boist → ['B', 'B', 'G', 'G', 'G']\n",
      "Attempt 4: puist → ['B', 'B', 'G', 'G', 'G']\n",
      "Attempt 5: whist → ['B', 'B', 'G', 'G', 'G']\n",
      "Attempt 6: idist → ['G', 'G', 'G', 'G', 'G']\n",
      "Solved idist in 6 attempts!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# We initialise the word statistics for the solver\n",
    "# (i.e. the positional frequency of each letter and the global letter frequency)\n",
    "positional_freq = [defaultdict(int) for _ in range(5)]\n",
    "\n",
    "for word in words_data:\n",
    "    for pos in range(5):\n",
    "        char = word[pos]\n",
    "        positional_freq[pos][char] += 1\n",
    "\n",
    "letter_frequency = Counter(itertools.chain.from_iterable(words_data))\n",
    "\n",
    "# Normalize the letter frequencies\n",
    "total_words = len(words_data)\n",
    "for char, freq in letter_frequency.items():\n",
    "    letter_frequency[char] = freq / total_words\n",
    "\n",
    "# Normalize the positional frequencies\n",
    "for pos in range(5):\n",
    "    total_pos = sum(positional_freq[pos].values())\n",
    "    for char, freq in positional_freq[pos].items():\n",
    "        positional_freq[pos][char] = freq / total_pos\n",
    "\n",
    "\n",
    "print(f\"positional_freq: {positional_freq}\")\n",
    "print(f\"letter_frequency: {letter_frequency}\")\n",
    "\n",
    "# Precompute scores for all words\n",
    "coef_pos_freq = 5\n",
    "coef_let_freq = 1\n",
    "coef_dup = 1\n",
    "word_scores = []\n",
    "for word in words_data:\n",
    "    score = sum(\n",
    "        coef_pos_freq * positional_freq[pos][char]\n",
    "        + coef_let_freq * letter_frequency[char]\n",
    "        + coef_dup * len(set(word))\n",
    "        for pos, char in enumerate(word)\n",
    "    )\n",
    "    word_scores.append((score, tuple(word)))\n",
    "\n",
    "# Sort words by descending score\n",
    "word_scores.sort(reverse=True, key=lambda x: x[0])\n",
    "sorted_words = [word for (score, word) in word_scores]\n",
    "\n",
    "def filter_valid_words(words_data, guess, feedback):\n",
    "    valid = []\n",
    "    for word in words_data:\n",
    "        valid_word = True\n",
    "        # Check green constraints\n",
    "        for pos in range(5):\n",
    "            if feedback[pos] == 'G' and word[pos] != guess[pos]:\n",
    "                valid_word = False\n",
    "                break\n",
    "        if not valid_word:\n",
    "            continue\n",
    "\n",
    "        # Check yellow constraints\n",
    "        for pos in range(5):\n",
    "            if feedback[pos] == 'Y':\n",
    "                if word[pos] == guess[pos] or guess[pos] not in word:\n",
    "                    valid_word = False\n",
    "                    break\n",
    "        if not valid_word:\n",
    "            continue\n",
    "\n",
    "        # Check gray constraints\n",
    "        gray_chars = [guess[pos] for pos in range(5) if feedback[pos] == 'B']\n",
    "        for char in gray_chars:\n",
    "            if char in word and char not in [guess[p] for p in range(5) if feedback[p] in ('G', 'Y')]:\n",
    "                valid_word = False\n",
    "                break\n",
    "\n",
    "        if valid_word:\n",
    "            valid.append(word)\n",
    "    return valid\n",
    "\n",
    "\n",
    "def solve_wordle(target_word, max_attempts=6):\n",
    "    target_as_int = tuple(ord(c) - ord('a') for c in target_word)\n",
    "    valid_words = sorted_words.copy()  # Use precomputed sorted list\n",
    "\n",
    "    for attempt in range(max_attempts):\n",
    "        if not valid_words:\n",
    "            print(\"No valid guesses left!\")\n",
    "            return\n",
    "\n",
    "        # for i in range(len(valid_words)):\n",
    "            # print(''.join([chr(c + ord('a')) for c in valid_words[i]]))\n",
    "\n",
    "        # Pick the highest-scoring valid word\n",
    "        best_guess = valid_words[0]\n",
    "        guess_str = ''.join([chr(c + ord('a')) for c in best_guess])\n",
    "        feedback = get_feedback(best_guess, target_as_int)\n",
    "        print(f\"Attempt {attempt+1}: {guess_str} → {feedback}\")\n",
    "\n",
    "        if feedback == ['G'] * 5:\n",
    "            print(f\"Solved {target_word} in {attempt+1} attempts!\")\n",
    "            return\n",
    "\n",
    "        # Filter valid words based on feedback\n",
    "        valid_words = filter_valid_words(valid_words, best_guess, feedback)\n",
    "\n",
    "    print(f\"Failed to solve {target_word} in {max_attempts} attempts.\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "random_word = random.choice(words[\"words\"].to_list())\n",
    "print(f\"Random word: {random_word}\")\n",
    "solve_wordle(random_word, 100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
